import os
import json
import numpy as np
import faiss
import openai
from dotenv import load_dotenv

# === åˆæœŸè¨­å®š ===
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# === ãƒ‘ã‚¹è¨­å®šï¼ˆäºˆç´„ç”¨ï¼‰ ===
FAQ_PATH = "data/reserve_faq.json"
KNOWLEDGE_PATH = "data/reserve_knowledge.json"
VECTOR_PATH = "data/reserve_vector_data.npy"
INDEX_PATH = "data/reserve_index.faiss"
EMBED_MODEL = "text-embedding-3-small"

# === Embeddingå–å¾—é–¢æ•° ===
def get_embedding(text):
    response = openai.embeddings.create(
        model=EMBED_MODEL,
        input=text
    )
    return np.array(response.data[0].embedding, dtype="float32")

# === ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ===
with open(FAQ_PATH, "r", encoding="utf-8") as f:
    faq_items = json.load(f)
faq_questions = [item["question"] for item in faq_items]

with open(KNOWLEDGE_PATH, "r", encoding="utf-8") as f:
    knowledge_data = json.load(f)

# reserve_knowledge.json ã¯ list æ§‹é€ ï¼ˆtitle, contentï¼‰ã‚’æƒ³å®š
if isinstance(knowledge_data, list):
    knowledge_contents = [
        f"{item['title']}ï¼š{item['content']}" for item in knowledge_data
    ]
else:
    raise ValueError("reserve_knowledge.json ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")

# === ã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ ===
search_corpus = faq_questions + knowledge_contents

# === ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ & ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ ===
print("ğŸ”„ äºˆç´„ç”¨ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆä¸­...")
vector_data = np.array([get_embedding(text) for text in search_corpus], dtype="float32")

print("ğŸ§  FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ...")
index = faiss.IndexFlatL2(vector_data.shape[1])
index.add(vector_data)

# === ä¿å­˜ ===
print("ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­...")
np.save(VECTOR_PATH, vector_data)
faiss.write_index(index, INDEX_PATH)

print("âœ… äºˆç´„ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
